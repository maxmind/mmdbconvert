# Query-Optimized Parquet Configuration
# This configuration demonstrates best practices for Parquet files that will be
# queried by analytics engines like DuckDB, Apache Spark, or Trino.
#
# Key optimization: Integer columns (start_int, end_int) come FIRST.
# This enables efficient predicate pushdown and row group skipping, resulting
# in 10-100x faster IP lookup queries.
#
# See docs/parquet-queries.md for query examples and performance details.

[output]
format = "parquet"
file = "geo-optimized.parquet"

[output.parquet]
compression = "snappy"              # Best balance for analytics queries
row_group_size = 500000             # ~250 MB per row group for optimal parallelism
# To split IPv4/IPv6 output, configure output.ipv4_file and output.ipv6_file in the [output] section

# CRITICAL: Integer columns FIRST for query performance
# Query engines use min/max statistics on these columns to skip entire row groups
[[network.columns]]
name = "start_int"
type = "start_int"

[[network.columns]]
name = "end_int"
type = "end_int"

# Optional: Add human-readable columns for debugging
[[network.columns]]
name = "network_cidr"
type = "cidr"

# Database
[[databases]]
name = "enterprise"
path = "/var/lib/GeoIP/GeoIP2-Enterprise.mmdb"

# Data columns with appropriate type hints for query performance
[[columns]]
name = "country_iso"
database = "enterprise"
path = ["country", "iso_code"]
type = "string"

[[columns]]
name = "country_name"
database = "enterprise"
path = ["country", "names", "en"]
type = "string"

[[columns]]
name = "city_name"
database = "enterprise"
path = ["city", "names", "en"]
type = "string"

# Use native numeric types for better query performance and compression
[[columns]]
name = "latitude"
database = "enterprise"
path = ["location", "latitude"]
type = "float64"

[[columns]]
name = "longitude"
database = "enterprise"
path = ["location", "longitude"]
type = "float64"

[[columns]]
name = "accuracy_radius"
database = "enterprise"
path = ["location", "accuracy_radius"]
type = "int64"

# Boolean type for flags
[[columns]]
name = "is_in_european_union"
database = "enterprise"
path = ["country", "is_in_european_union"]
type = "bool"

# Query example for this optimized file:
#
# -- DuckDB: Lookup IP 203.0.113.100 (integer: 3405803876)
# SELECT * FROM read_parquet('geo-optimized.parquet')
# WHERE start_int <= 3405803876 AND end_int >= 3405803876;
#
# The query engine will:
# 1. Check row group statistics for start_int and end_int
# 2. Skip row groups that can't contain the IP (90-95% of data)
# 3. Only scan 1-2 row groups out of 20+ total
# 4. Result: 10-100x faster than scanning all data
